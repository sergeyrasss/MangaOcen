import os
import requests
from datetime import datetime
import time
import subprocess
import atexit

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
DOWNLOAD_FOLDER = 'downloaded_images'
os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—Ä–µ—Ç–∞ —Å–Ω–∞ —Å–∏—Å—Ç–µ–º—ã
def inhibit_sleep():
    try:
        # –°–æ–∑–¥–∞–µ–º inhibitor —á–µ—Ä–µ–∑ systemd
        cmd = [
            'systemd-inhibit',
            '--what=idle:sleep:shutdown',
            '--who=DesuCityDownloader',
            '--why=Downloading_images',
            '--mode=block',
            'python3', os.path.abspath(__file__)
        ]
        # –ï—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
        if os.environ.get('INHIBIT_RUN'):
            return None
        # –ò–Ω–∞—á–µ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–µ–±—è —á–µ—Ä–µ–∑ inhibitor
        os.environ['INHIBIT_RUN'] = '1'
        subprocess.run(cmd)
        exit()
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—Ä–µ—Ç–∏—Ç—å —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º: {e}")

# –í—ã–∑—ã–≤–∞–µ–º –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
inhibit_sleep()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ —Å–Ω–∞
def restore_sleep():
    print("\nüîÑ –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º —Å–Ω–∞ —Å–∏—Å—Ç–µ–º—ã...")

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ
atexit.register(restore_sleep)

# –ß—Ç–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫
with open('grand_blue_images.txt', 'r') as f:
    image_urls = [line.strip() for line in f if line.strip()]

# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã
headers = {
    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Referer': 'https://desu.city/',
    'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8'
}

success_count = 0
fail_count = 0
failed_urls = []

print(f"üöÄ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ {len(image_urls)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

for i, url in enumerate(image_urls, 1):
    try:
        filename = os.path.join(DOWNLOAD_FOLDER, os.path.basename(url))
        
        if os.path.exists(filename):
            print(f"‚è© [{i}/{len(image_urls)}] –£–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {filename}")
            success_count += 1
            continue
            
        print(f"‚¨áÔ∏è [{i}/{len(image_urls)}] –ó–∞–≥—Ä—É–∑–∫–∞: {url}")
        
        response = requests.get(url, headers=headers, stream=True, timeout=30)
        response.raise_for_status()
        
        with open(filename, 'wb') as f:
            for chunk in response.iter_content(1024):
                f.write(chunk)
        
        success_count += 1
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
        time.sleep(1)
        
    except requests.exceptions.RequestException as e:
        fail_count += 1
        failed_urls.append(url)
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {str(e)}")
    except Exception as e:
        fail_count += 1
        failed_urls.append(url)
        print(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")

print(f"\nüìä –ò—Ç–æ–≥–∏: –£—Å–ø–µ—à–Ω–æ - {success_count}, –û—à–∏–±–æ–∫ - {fail_count}")

if failed_urls:
    print("\n–°—Å—ã–ª–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å:")
    for url in failed_urls:
        print(f"- {url}")